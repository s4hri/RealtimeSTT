# This file was autogenerated by uv via the following command:
#    uv export --format requirements.txt --no-hashes -o requirements.locked.txt
anyio==4.12.1
    # via httpx
av==16.1.0
    # via faster-whisper
certifi==2026.1.4
    # via
    #   httpcore
    #   httpx
    #   requests
cffi==2.0.0
    # via soundfile
charset-normalizer==3.4.4
    # via requests
click==8.3.1
    # via typer-slim
colorama==0.4.6
    # via
    #   click
    #   halo
    #   log-symbols
    #   tqdm
coloredlogs==15.0.1
    # via onnxruntime
ctranslate2==4.6.3
    # via faster-whisper
enum34==1.1.10
    # via pvporcupine
exceptiongroup==1.3.1 ; python_full_version < '3.11'
    # via anyio
faster-whisper==1.1.1
    # via tests
filelock==3.20.3
    # via
    #   huggingface-hub
    #   torch
flatbuffers==25.12.19
    # via onnxruntime
fsspec==2026.1.0
    # via
    #   huggingface-hub
    #   torch
h11==0.16.0
    # via httpcore
halo==0.0.31
    # via tests
hf-xet==1.2.0 ; platform_machine == 'AMD64' or platform_machine == 'aarch64' or platform_machine == 'amd64' or platform_machine == 'arm64' or platform_machine == 'x86_64'
    # via huggingface-hub
httpcore==1.0.9
    # via httpx
httpx==0.28.1
    # via huggingface-hub
huggingface-hub==1.3.1
    # via
    #   faster-whisper
    #   tokenizers
humanfriendly==10.0
    # via coloredlogs
idna==3.11
    # via
    #   anyio
    #   httpx
    #   requests
jinja2==3.1.6
    # via torch
joblib==1.5.3
    # via scikit-learn
log-symbols==0.0.14
    # via halo
markdown-it-py==4.0.0
    # via rich
markupsafe==3.0.3
    # via jinja2
mdurl==0.1.2
    # via markdown-it-py
mpmath==1.3.0
    # via sympy
networkx==3.4.2 ; python_full_version < '3.11'
    # via torch
networkx==3.6.1 ; python_full_version >= '3.11'
    # via torch
numpy==1.26.4
    # via
    #   ctranslate2
    #   onnxruntime
    #   pvporcupine
    #   scikit-learn
    #   scipy
    #   soundfile
    #   tests
    #   tflite-runtime
nvidia-cublas-cu12==12.8.4.1 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.8.90 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cuda-nvrtc-cu12==12.8.93 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cuda-runtime-cu12==12.8.90 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cudnn-cu12==9.10.2.21 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cufft-cu12==11.3.3.83 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cufile-cu12==1.13.1.3 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-curand-cu12==10.3.9.90 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cusolver-cu12==11.7.3.90 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cusparse-cu12==12.5.8.93 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cusparselt-cu12==0.7.1 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-nccl-cu12==2.27.5 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-nvjitlink-cu12==12.8.93 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via
    #   nvidia-cufft-cu12
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
    #   torch
nvidia-nvshmem-cu12==3.3.20 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-nvtx-cu12==12.8.90 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
onnxruntime==1.16.3
    # via
    #   faster-whisper
    #   openwakeword
    #   tests
openwakeword==0.6.0
    # via tests
packaging==25.0
    # via
    #   huggingface-hub
    #   onnxruntime
protobuf==6.33.4
    # via onnxruntime
pvporcupine==1.9.5
    # via tests
pyaudio==0.2.14
    # via tests
pycparser==2.23 ; implementation_name != 'PyPy'
    # via cffi
pygments==2.19.2
    # via rich
pyreadline3==3.5.4 ; sys_platform == 'win32'
    # via humanfriendly
pyyaml==6.0.3
    # via
    #   ctranslate2
    #   huggingface-hub
requests==2.32.5
    # via openwakeword
rich==14.2.0
    # via tests
scikit-learn==1.7.2 ; python_full_version < '3.11'
    # via openwakeword
scikit-learn==1.8.0 ; python_full_version >= '3.11'
    # via openwakeword
scipy==1.15.2
    # via
    #   openwakeword
    #   scikit-learn
    #   tests
setuptools==80.9.0
    # via
    #   ctranslate2
    #   torch
shellingham==1.5.4
    # via huggingface-hub
six==1.17.0
    # via halo
soundfile==0.13.1
    # via tests
spinners==0.0.24
    # via halo
sympy==1.14.0
    # via
    #   onnxruntime
    #   torch
termcolor==3.3.0
    # via halo
tflite-runtime==2.14.0 ; sys_platform == 'linux'
    # via openwakeword
threadpoolctl==3.6.0
    # via scikit-learn
tokenizers==0.22.2
    # via faster-whisper
torch==2.9.1
    # via
    #   tests
    #   torchaudio
torchaudio==2.9.1
    # via tests
tqdm==4.67.1
    # via
    #   faster-whisper
    #   huggingface-hub
    #   openwakeword
triton==3.5.1 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
typer-slim==0.21.1
    # via huggingface-hub
typing-extensions==4.15.0
    # via
    #   anyio
    #   exceptiongroup
    #   huggingface-hub
    #   torch
    #   typer-slim
urllib3==2.6.3
    # via requests
webrtcvad-wheels==2.0.14
    # via tests
websocket-client==1.8.0
    # via tests
websockets==15.0.1
    # via tests
